{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f057dbc4-5a92-4751-837f-a08f93f5f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing import Dict, Any, List, Tuple, TypedDict\n",
    "from langgraph.graph import Graph, StateGraph\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import ast\n",
    "import re\n",
    "\n",
    "mistral = LlamaCpp(\n",
    "    model_path=\"C:/Users/DaysPC/Langgraph/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2000,\n",
    "    n_ctx=32768,\n",
    "    top_p=0.95,\n",
    "    n_batch=64,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simulate web search.\"\"\"\n",
    "    return f\"Found results for: {query}\"\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def write_file(content: str) -> str:\n",
    "    \"\"\"Simulate writing content to a file.\"\"\"\n",
    "    return f\"Successfully wrote: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45ccbc6-7532-48ed-83de-8e58291fdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanAgent:\n",
    "    def __init__(self, model: LlamaCpp):\n",
    "        self.model = model\n",
    "\n",
    "    def create_plan(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Break down the query into 3 structured tasks.\"\"\"\n",
    "\n",
    "        prompt = f\"\"\"[INST] Break this task into exactly 3 simple steps:\n",
    "Task: {query}\n",
    "\n",
    "Create 3 separate tasks:\n",
    "1. First find/search for the required information\n",
    "2. Then perform the calculation or action on that information\n",
    "3. Finally, analyze or explain the trend or historical change related to the query\n",
    "\n",
    "Format as a Python list with exactly 3 dictionaries:\n",
    "[\n",
    "    {{\"task_id\": 1, \"description\": \"Search for specific information\", \"status\": \"pending\"}},\n",
    "    {{\"task_id\": 2, \"description\": \"Perform calculation with the found information\", \"status\": \"pending\"}},\n",
    "    {{\"task_id\": 3, \"description\": \"Analyze how it has changed over time\", \"status\": \"pending\"}}\n",
    "]\n",
    "\n",
    "Return only the Python list.[/INST]</s>\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.invoke(prompt)\n",
    "            response = response.strip()\n",
    "            tasks = ast.literal_eval(response)\n",
    "            \n",
    "            if not isinstance(tasks, list) or len(tasks) != 3:\n",
    "                raise ValueError(\"Model did not return exactly 3 tasks.\")\n",
    "            \n",
    "            cleaned_tasks = []\n",
    "            for i, task in enumerate(tasks, 1):\n",
    "                if not isinstance(task, dict) or \"description\" not in task:\n",
    "                    raise ValueError(f\"Invalid task format at index {i}\")\n",
    "                cleaned_tasks.append({\n",
    "                    \"task_id\": i,\n",
    "                    \"description\": task[\"description\"],\n",
    "                    \"status\": \"pending\"\n",
    "                })\n",
    "\n",
    "            return cleaned_tasks\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            return [\n",
    "                {\n",
    "                    \"task_id\": 1,\n",
    "                    \"description\": f\"Search for information: {query}\",\n",
    "                    \"status\": \"pending\"\n",
    "                },\n",
    "                {\n",
    "                    \"task_id\": 2,\n",
    "                    \"description\": \"Process the found information\",\n",
    "                    \"status\": \"pending\"\n",
    "                },\n",
    "                {\n",
    "                    \"task_id\": 3,\n",
    "                    \"description\": \"Analyze how it changed historically\",\n",
    "                    \"status\": \"pending\"\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc69cf5-2cc0-463a-adbe-7cd5437f9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, tools: List, model):\n",
    "        self.model = model\n",
    "        self.calculator = next(t for t in tools if t.name == \"calculator\")\n",
    "        self.current_population = None\n",
    "        self.population_history = {}\n",
    "        self.location = None\n",
    "\n",
    "    def _extract_location(self, text: str) -> str:\n",
    "        prompt = f\"\"\"[INST] Extract only the location name from the following user query:\n",
    "{text}\n",
    "Return only the location name, nothing else.[/INST]\"\"\"\n",
    "        result = self.model.invoke(prompt).strip()\n",
    "        if not result or \"unable\" in result.lower() or len(result.split()) > 5:\n",
    "            return \"New York City\"\n",
    "        return result\n",
    "\n",
    "    def _get_current_population(self, location: str) -> int:\n",
    "        prompt = f\"What is the current population of {location} in 2021?\"\n",
    "        response = self.model.invoke(prompt)\n",
    "        response_text = response if isinstance(response, str) else str(response)\n",
    "\n",
    "        match = re.search(r\"(\\d{1,3}(?:,\\d{3})+)\", response_text)\n",
    "        if match:\n",
    "            try:\n",
    "                return int(match.group(1).replace(\",\", \"\"))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        match_million = re.search(r\"([\\d.]+)\\s*(million|billion)\", response_text, re.IGNORECASE)\n",
    "        if match_million:\n",
    "            number = float(match_million.group(1))\n",
    "            scale = match_million.group(2).lower()\n",
    "            multiplier = 1_000_000 if scale == \"million\" else 1_000_000_000\n",
    "            return int(number * multiplier)\n",
    "\n",
    "        raise ValueError(f\"Could not extract population from: {response_text}\")\n",
    "\n",
    "    def _get_population_history(self, location: str) -> Dict[str, int]:\n",
    "        prompt = f\"\"\"[INST] Give population estimates of {location} in 1990, 2000, and 2010.\n",
    "Only include the year and number in each sentence. Use millions if necessary.[/INST]\"\"\"\n",
    "        response = self.model.invoke(prompt)\n",
    "        response_text = getattr(response, \"content\", str(response))\n",
    "\n",
    "        matches = re.findall(r'(\\d{4}).*?([\\d.]+)\\s*million', response_text, re.IGNORECASE)\n",
    "        if not matches:\n",
    "            raise ValueError(\"Could not parse historical population.\")\n",
    "\n",
    "        return {year: int(float(pop_mil) * 1_000_000) for year, pop_mil in matches}\n",
    "\n",
    "    def execute_task(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        try:\n",
    "            task_id = task.get(\"task_id\")\n",
    "\n",
    "            if task_id == 1:\n",
    "                desc = task.get(\"description\", \"\")\n",
    "                location = self._extract_location(desc)\n",
    "                pop = self._get_current_population(location)\n",
    "\n",
    "                if not (100_000 <= pop <= 2_000_000_000):\n",
    "                    raise ValueError(\"Population value out of expected range\")\n",
    "\n",
    "                self.current_population = pop\n",
    "                self.location = location\n",
    "\n",
    "                return {\n",
    "                    **task,\n",
    "                    \"status\": \"completed\",\n",
    "                    \"result\": f\"Population of {location}: {pop:,}\",\n",
    "                    \"tool_used\": \"language_model\"\n",
    "                }\n",
    "\n",
    "            elif task_id == 2:\n",
    "                if self.current_population is None:\n",
    "                    raise ValueError(\"Missing population data from Task 1\")\n",
    "                calc = f\"{self.current_population} * 0.15\"\n",
    "                result = self.calculator.run(calc)\n",
    "                return {\n",
    "                    **task,\n",
    "                    \"status\": \"completed\",\n",
    "                    \"result\": f\"15% of {self.current_population:,} = {float(result):,.2f}\",\n",
    "                    \"tool_used\": \"calculator\"\n",
    "                }\n",
    "\n",
    "            elif task_id == 3:\n",
    "                if not self.location:\n",
    "                    raise ValueError(\"Location not found from previous task\")\n",
    "\n",
    "                history = self._get_population_history(self.location)\n",
    "                self.population_history = history\n",
    "\n",
    "                diffs = []\n",
    "                for year, past_pop in history.items():\n",
    "                    growth = self.current_population - past_pop\n",
    "                    percent = (growth / past_pop) * 100\n",
    "                    diffs.append(f\"{year} → Now: Growth = {growth:,} ({percent:.1f}%)\")\n",
    "\n",
    "                summary = \"\\n\".join(diffs)\n",
    "                return {\n",
    "                    **task,\n",
    "                    \"status\": \"completed\",\n",
    "                    \"result\": f\"Population growth for {self.location}:\\n{summary}\",\n",
    "                    \"tool_used\": \"model_history_analysis\"\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown task_id: {task_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **task,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e),\n",
    "                \"result\": f\"Task failed due to error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def reflect_on_result(self, task: Dict[str, Any]) -> str:\n",
    "        if task[\"status\"] == \"completed\":\n",
    "            if task[\"task_id\"] == 1:\n",
    "                return \"Retrieved current population data successfully.\"\n",
    "            elif task[\"task_id\"] == 2:\n",
    "                return \"Performed calculation successfully.\"\n",
    "            elif task[\"task_id\"] == 3:\n",
    "                return \"Historical analysis completed.\"\n",
    "        return f\"Task {task['task_id']} failed: {task.get('error', 'Unknown error')}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096969f3-89c5-431a-a0a1-45c9bf2b5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowState(TypedDict):\n",
    "    query: str\n",
    "    tasks: List[Dict[str, Any]]\n",
    "    current_task_id: int\n",
    "    completed: bool\n",
    "    steps: int\n",
    "    last_node: str\n",
    "\n",
    "\n",
    "def create_workflow(tools: List[Tool], model: LlamaCpp) -> Graph:\n",
    "    \"\"\"Create an advanced automated workflow for sequential task execution.\"\"\"\n",
    "\n",
    "    plan_agent = PlanAgent(model)\n",
    "    tool_agent = ToolAgent(tools, model)\n",
    "\n",
    "    def plan(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Create a plan from query if not already present.\"\"\"\n",
    "        if not state[\"tasks\"]:\n",
    "            state[\"tasks\"] = plan_agent.create_plan(state[\"query\"])\n",
    "            state[\"steps\"] = 0\n",
    "            state[\"last_node\"] = \"plan\"\n",
    "            state[\"current_task_id\"] = 1\n",
    "        return state\n",
    "\n",
    "    def execute(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Execute current task using the appropriate tool.\"\"\"\n",
    "        state[\"steps\"] += 1\n",
    "        state[\"last_node\"] = \"execute\"\n",
    "\n",
    "        current_task = next(\n",
    "            (t for t in state[\"tasks\"] if t[\"task_id\"] == state[\"current_task_id\"]),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if current_task and current_task[\"status\"] == \"pending\":\n",
    "            result = tool_agent.execute_task(current_task)\n",
    "\n",
    "            state[\"tasks\"] = [\n",
    "                result if t[\"task_id\"] == current_task[\"task_id\"] else t\n",
    "                for t in state[\"tasks\"]\n",
    "            ]\n",
    "\n",
    "            if state[\"current_task_id\"] < len(state[\"tasks\"]):\n",
    "                state[\"current_task_id\"] += 1\n",
    "            else:\n",
    "                state[\"completed\"] = True\n",
    "\n",
    "        return state\n",
    "\n",
    "    def should_continue(state: WorkflowState) -> Tuple[bool, str]:\n",
    "        \"\"\"Determine whether to continue workflow or stop.\"\"\"\n",
    "        if state[\"completed\"]:\n",
    "            return False, \"end\"\n",
    "\n",
    "        if state[\"steps\"] >= 10:\n",
    "            state[\"completed\"] = True\n",
    "            return False, \"end\"\n",
    "\n",
    "        if not state[\"tasks\"]:\n",
    "            return True, \"plan\"\n",
    "\n",
    "        current_task = next(\n",
    "            (t for t in state[\"tasks\"] if t[\"task_id\"] == state[\"current_task_id\"]),\n",
    "            None\n",
    "        )\n",
    "\n",
    "        if current_task and current_task[\"status\"] == \"pending\":\n",
    "            return True, \"execute\"\n",
    "\n",
    "        if state[\"current_task_id\"] < len(state[\"tasks\"]):\n",
    "            return True, \"execute\"\n",
    "\n",
    "        state[\"completed\"] = True\n",
    "        return False, \"end\"\n",
    "\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "\n",
    "    workflow.add_node(\"plan\", plan)\n",
    "    workflow.add_node(\"execute\", execute)\n",
    "\n",
    "    workflow.set_entry_point(\"plan\")\n",
    "\n",
    "    workflow.add_conditional_edges(\"plan\", should_continue)\n",
    "    workflow.add_conditional_edges(\"execute\", should_continue)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def run_workflow(graph: Graph, query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Run a compiled workflow with a given query.\"\"\"\n",
    "    initial_state: WorkflowState = {\n",
    "        \"query\": query,\n",
    "        \"tasks\": [],\n",
    "        \"current_task_id\": 1,\n",
    "        \"completed\": False,\n",
    "        \"steps\": 0,\n",
    "        \"last_node\": \"\"\n",
    "    }\n",
    "    return graph.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80bfdd97-4d94-4378-87eb-943ea2746658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workflow completed!\n",
      "\n",
      "Tasks and Results:\n",
      "\n",
      "Task 1:\n",
      "Description: Search for specific information\n",
      "Status: completed\n",
      "Result: Population of New York City: 8,336,817\n",
      "\n",
      "Task 2:\n",
      "Description: Perform calculation with the found information\n",
      "Status: completed\n",
      "Result: 15% of 8,336,817 = 1,250,522.55\n",
      "\n",
      "Task 3:\n",
      "Description: Analyze how it has changed over time\n",
      "Status: completed\n",
      "Result: Population growth for New York City:\n",
      "1990 → Now: Growth = 836,817 (11.2%)\n",
      "2000 → Now: Growth = 236,817 (2.9%)\n",
      "2010 → Now: Growth = -63,183 (-0.8%)\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_search\",\n",
    "        func=search_web,\n",
    "        description=\"Search the web for information.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"calculator\",\n",
    "        func=calculate,\n",
    "        description=\"Calculate mathematical expressions.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"file_writer\",\n",
    "        func=write_file,\n",
    "        description=\"Write content to a file.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "try:\n",
    "    workflow = create_workflow(tools, mistral)\n",
    "\n",
    "    query = \"Find the population of New York City and calculate 15% of it, How has it changed over the years\"\n",
    "\n",
    "    result = run_workflow(workflow, query)\n",
    "\n",
    "    print(\"\\nWorkflow completed!\")\n",
    "    print(\"\\nTasks and Results:\")\n",
    "    for task in result[\"tasks\"]:\n",
    "        print(f\"\\nTask {task['task_id']}:\")\n",
    "        print(f\"Description: {task['description']}\")\n",
    "        print(f\"Status: {task['status']}\")\n",
    "        if \"result\" in task:\n",
    "            print(f\"Result: {task['result']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during workflow execution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (core_env)",
   "language": "python",
   "name": "core_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
