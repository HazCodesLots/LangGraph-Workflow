{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f057dbc4-5a92-4751-837f-a08f93f5f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing import Dict, Any, List, Tuple, TypedDict\n",
    "from langgraph.graph import Graph, StateGraph\n",
    "import json\n",
    "\n",
    "# Initialize Mistral model\n",
    "mistral = LlamaCpp(\n",
    "    model_path=\"C:/Users/DaysPC/Langgraph/mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2000,\n",
    "    n_ctx=4096,\n",
    "    top_p=0.95,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Define tool functions\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Simulate web search.\"\"\"\n",
    "    return f\"Found results for: {query}\"\n",
    "\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def write_file(content: str) -> str:\n",
    "    \"\"\"Simulate writing content to a file.\"\"\"\n",
    "    return f\"Successfully wrote: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45ccbc6-7532-48ed-83de-8e58291fdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanAgent:\n",
    "    def __init__(self, model: LlamaCpp):\n",
    "        self.model = model\n",
    "        \n",
    "    def create_plan(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Create a plan by breaking down the query into subtasks.\"\"\"\n",
    "        prompt = f\"\"\"<s>[INST] Break this task into exactly 2 simple steps:\n",
    "        Task: {query}\n",
    "        \n",
    "        Create 2 separate tasks:\n",
    "        1. First find/search for the required information\n",
    "        2. Then perform the calculation or action on that information\n",
    "        \n",
    "        Format as a Python list with exactly 2 dictionaries:\n",
    "        [\n",
    "            {{\"task_id\": 1, \"description\": \"Search for specific information\", \"status\": \"pending\"}},\n",
    "            {{\"task_id\": 2, \"description\": \"Perform calculation with the found information\", \"status\": \"pending\"}}\n",
    "        ]\n",
    "        \n",
    "        Return only the Python list.[/INST]</s>\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.invoke(prompt)\n",
    "            # Clean and parse the response\n",
    "            response_clean = response.strip().split('[')[1].split(']')[0]\n",
    "            response_clean = f\"[{response_clean}]\"\n",
    "            tasks = eval(response_clean)\n",
    "            \n",
    "            # Validate tasks\n",
    "            if not tasks or len(tasks) == 0:\n",
    "                raise ValueError(\"No tasks created\")\n",
    "                \n",
    "            # Ensure proper task structure\n",
    "            cleaned_tasks = []\n",
    "            for i, task in enumerate(tasks, 1):\n",
    "                cleaned_tasks.append({\n",
    "                    \"task_id\": i,\n",
    "                    \"description\": task.get(\"description\", f\"Step {i} of: {query}\"),\n",
    "                    \"status\": \"pending\"\n",
    "                })\n",
    "            return cleaned_tasks\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to basic task breakdown\n",
    "            return [\n",
    "                {\n",
    "                    \"task_id\": 1,\n",
    "                    \"description\": f\"Search for information: {query}\",\n",
    "                    \"status\": \"pending\"\n",
    "                },\n",
    "                {\n",
    "                    \"task_id\": 2,\n",
    "                    \"description\": f\"Process the found information\",\n",
    "                    \"status\": \"pending\"\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc69cf5-2cc0-463a-adbe-7cd5437f9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolAgent:\n",
    "    def __init__(self, tools: List[Tool], model: LlamaCpp):\n",
    "        self.tools = tools\n",
    "        self.model = model\n",
    "        self.task_results = {}  # Store results for dependency handling\n",
    "        \n",
    "    def execute_task(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a single task using available tools.\"\"\"\n",
    "        # Determine tool based on task type\n",
    "        if \"search\" in task[\"description\"].lower() or \"find\" in task[\"description\"].lower():\n",
    "            tool_name = \"web_search\"\n",
    "        elif any(word in task[\"description\"].lower() for word in [\"calculate\", \"compute\", \"percent\", \"%\"]):\n",
    "            tool_name = \"calculator\"\n",
    "        elif any(word in task[\"description\"].lower() for word in [\"save\", \"write\", \"store\"]):\n",
    "            tool_name = \"file_writer\"\n",
    "        else:\n",
    "            # Fallback to asking the model\n",
    "            tool_prompt = f\"\"\"[INST] Which tool should be used for this task?\n",
    "            TASK: {task['description']}\n",
    "            Choose from: web_search, calculator, or file_writer\n",
    "            Return only the tool name.[/INST]\"\"\"\n",
    "            tool_name = self.model.invoke(tool_prompt).strip().lower()\n",
    "\n",
    "        tool = next((t for t in self.tools if t.name.lower() == tool_name), None)\n",
    "        \n",
    "        if not tool:\n",
    "            return {\n",
    "                **task,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": f\"No matching tool found: {tool_name}\"\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            # Handle different tools appropriately\n",
    "            if tool_name == \"calculator\":\n",
    "                # For calculator, extract numbers from previous results if needed\n",
    "                if task[\"task_id\"] > 1:\n",
    "                    prev_result = self.task_results.get(task[\"task_id\"] - 1, \"\")\n",
    "                    if \"Found results for\" in prev_result:\n",
    "                        # Simulate getting actual population number (in real app, would parse from search)\n",
    "                        population = \"8336817\"  # NYC population 2023 estimate\n",
    "                        if \"15%\" in task[\"description\"]:\n",
    "                            tool_input = f\"{population} * 0.15\"\n",
    "                        else:\n",
    "                            tool_input = population\n",
    "                    else:\n",
    "                        tool_input = prev_result\n",
    "                else:\n",
    "                    tool_input = task[\"description\"]\n",
    "                    \n",
    "            elif tool_name == \"web_search\":\n",
    "                # For web search, use description directly\n",
    "                tool_input = task[\"description\"]\n",
    "                \n",
    "            else:  # file_writer\n",
    "                tool_input = str(self.task_results.get(task[\"task_id\"] - 1, \"No data to write\"))\n",
    "\n",
    "            # Execute tool\n",
    "            result = tool.run(tool_input)\n",
    "            \n",
    "            # Store result for potential future use\n",
    "            self.task_results[task[\"task_id\"]] = result\n",
    "            \n",
    "            return {\n",
    "                **task,\n",
    "                \"status\": \"completed\",\n",
    "                \"result\": result,\n",
    "                \"tool_used\": tool_name\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                **task,\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e),\n",
    "                \"result\": f\"Failed to execute task: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    def reflect_on_result(self, task: Dict[str, Any]) -> str:\n",
    "        \"\"\"Provide feedback on task execution.\"\"\"\n",
    "        if task.get(\"status\") == \"completed\":\n",
    "            return f\"Successfully completed task {task['task_id']} using {task.get('tool_used', 'unknown tool')}\"\n",
    "        else:\n",
    "            return f\"Failed to complete task {task['task_id']}: {task.get('error', 'unknown error')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "096969f3-89c5-431a-a0a1-45c9bf2b5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowState(TypedDict):\n",
    "    query: str\n",
    "    tasks: List[Dict[str, Any]]\n",
    "    current_task_id: int\n",
    "    completed: bool\n",
    "    steps: int\n",
    "    last_node: str\n",
    "\n",
    "def create_workflow(tools: List[Tool], model: LlamaCpp) -> Graph:\n",
    "    \"\"\"Create a simplified workflow that executes tasks sequentially.\"\"\"\n",
    "    \n",
    "    # Initialize agents with the local model\n",
    "    plan_agent = PlanAgent(model)\n",
    "    tool_agent = ToolAgent(tools, model)\n",
    "    \n",
    "    def plan(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Create initial plan if no tasks exist.\"\"\"\n",
    "        if not state[\"tasks\"]:\n",
    "            state[\"tasks\"] = plan_agent.create_plan(state[\"query\"])\n",
    "            state[\"steps\"] = 0\n",
    "            state[\"last_node\"] = \"plan\"\n",
    "            state[\"current_task_id\"] = 1  # Start with first task\n",
    "        return state\n",
    "    \n",
    "    def execute(state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Execute current task.\"\"\"\n",
    "        state[\"steps\"] = state.get(\"steps\", 0) + 1\n",
    "        state[\"last_node\"] = \"execute\"\n",
    "        \n",
    "        # Get current task\n",
    "        current_task = next((t for t in state[\"tasks\"] \n",
    "                           if t[\"task_id\"] == state[\"current_task_id\"]), None)\n",
    "        \n",
    "        if current_task and current_task[\"status\"] == \"pending\":\n",
    "            # Execute the task\n",
    "            result = tool_agent.execute_task(current_task)\n",
    "            \n",
    "            # Update the task in state\n",
    "            state[\"tasks\"] = [\n",
    "                result if t[\"task_id\"] == current_task[\"task_id\"] else t\n",
    "                for t in state[\"tasks\"]\n",
    "            ]\n",
    "            \n",
    "            # Move to next task\n",
    "            if state[\"current_task_id\"] < len(state[\"tasks\"]):\n",
    "                state[\"current_task_id\"] += 1\n",
    "            else:\n",
    "                state[\"completed\"] = True\n",
    "                \n",
    "        return state\n",
    "    \n",
    "    def should_continue(state: WorkflowState) -> Tuple[bool, str]:\n",
    "        \"\"\"Determine next step in workflow.\"\"\"\n",
    "        # Stop if completed\n",
    "        if state[\"completed\"]:\n",
    "            return False, \"end\"\n",
    "            \n",
    "        # Stop if too many steps\n",
    "        if state[\"steps\"] >= 10:\n",
    "            state[\"completed\"] = True\n",
    "            return False, \"end\"\n",
    "            \n",
    "        # Initial planning\n",
    "        if not state[\"tasks\"]:\n",
    "            return True, \"plan\"\n",
    "        \n",
    "        # Check if current task needs execution\n",
    "        current_task = next((t for t in state[\"tasks\"] \n",
    "                           if t[\"task_id\"] == state[\"current_task_id\"]), None)\n",
    "        \n",
    "        if current_task and current_task[\"status\"] == \"pending\":\n",
    "            return True, \"execute\"\n",
    "        \n",
    "        # Check if there are more tasks\n",
    "        if state[\"current_task_id\"] < len(state[\"tasks\"]):\n",
    "            return True, \"execute\"\n",
    "        \n",
    "        # No more tasks to execute\n",
    "        state[\"completed\"] = True\n",
    "        return False, \"end\"\n",
    "    \n",
    "    # Create graph\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"plan\", plan)\n",
    "    workflow.add_node(\"execute\", execute)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"plan\")\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_conditional_edges(\"plan\", should_continue)\n",
    "    workflow.add_conditional_edges(\"execute\", should_continue)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "def run_workflow(graph: Graph, query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Run workflow with initial query.\"\"\"\n",
    "    initial_state: WorkflowState = {\n",
    "        \"query\": query,\n",
    "        \"tasks\": [],\n",
    "        \"current_task_id\": 1,\n",
    "        \"completed\": False,\n",
    "        \"steps\": 0,\n",
    "        \"last_node\": \"\"\n",
    "    }\n",
    "    return graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bfdd97-4d94-4378-87eb-943ea2746658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DaysPC\\anaconda3\\envs\\py310\\lib\\site-packages\\llama_cpp\\llama.py:1240: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Workflow completed!\n",
      "\n",
      "Tasks and Results:\n",
      "\n",
      "Task 1:\n",
      "Description: Search for the population of New York City\n",
      "Status: completed\n",
      "Result: Found results for: Search for the population of New York City\n",
      "\n",
      "Task 2:\n",
      "Description: Calculate 15% of the New York City population\n",
      "Status: completed\n",
      "Result: 1250522.55\n"
     ]
    }
   ],
   "source": [
    "# Create tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"web_search\",\n",
    "        func=search_web,\n",
    "        description=\"Search the web for information.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"calculator\",\n",
    "        func=calculate,\n",
    "        description=\"Calculate mathematical expressions.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"file_writer\",\n",
    "        func=write_file,\n",
    "        description=\"Write content to a file.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Create workflow with local Mistral model\n",
    "    workflow = create_workflow(tools, mistral)\n",
    "    \n",
    "    # Test query\n",
    "    query = \"Find the population of New York City and calculate 15% of it\"\n",
    "    \n",
    "    # Run workflow\n",
    "    result = run_workflow(workflow, query)\n",
    "    \n",
    "    print(\"\\nWorkflow completed!\")\n",
    "    print(\"\\nTasks and Results:\")\n",
    "    for task in result[\"tasks\"]:\n",
    "        print(f\"\\nTask {task['task_id']}:\")\n",
    "        print(f\"Description: {task['description']}\")\n",
    "        print(f\"Status: {task['status']}\")\n",
    "        if \"result\" in task:\n",
    "            print(f\"Result: {task['result']}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d80b0-d4fa-4d81-8dc2-96dffaa82bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
